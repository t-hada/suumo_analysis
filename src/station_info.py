import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import urllib.parse
import re
import time

def get_unique_stations(df: pd.DataFrame) -> np.ndarray:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã® access_1_station ~ access_3_station ã‹ã‚‰ã€
    æ¬ æå€¤ã‚„ç©ºæ–‡å­—ã‚’é™¤å¤–ã—ãŸã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªé§…åã®é…åˆ—ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚
    """
    # 3ã¤ã®åˆ—ã®å€¤ã‚’ä¸€æ¬¡å…ƒé…åˆ—ã«å±•é–‹ã—ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚‚ã®ã‚’å–å¾—
    cols = [col for col in ['access_1_station', 'access_2_station', 'access_3_station'] if col in df.columns]
    all_stations = pd.unique(df[cols].values.ravel())

    # NaN ã¨ ç©ºæ–‡å­—('') ã‚’é™¤å¤–
    valid_stations = [st for st in all_stations if not pd.isna(st) and st != '']

    return np.array(valid_stations)

def create_station_time_mapping(unique_stations: np.ndarray, to_station: str = 'æ±äº¬') -> pd.DataFrame:
    """
    ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªé§…ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€Yahoo!ä¹—æ›æ¡ˆå†…ã‹ã‚‰æŒ‡å®šé§…ã¾ã§ã®æ‰€è¦æ™‚é–“ã‚’å–å¾—ã€‚
    ç¬¬1ãƒ«ãƒ¼ãƒˆã®æ™‚é–“ã¨ä¹—ã‚Šæ›ãˆå›æ•°ã‚’å–å¾—ã™ã‚‹ã€‚
    """
    station_data = []
    print(f"å…¨ {len(unique_stations)} é§…ã®ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±å–å¾—ã‚’é–‹å§‹ã—ã¾ã™ï¼â˜•ï¸")

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    for i, st in enumerate(unique_stations, 1):
        station_clean = st.split('/')[-1] if '/' in st else st
        url = f"https://transit.yahoo.co.jp/search/result?from={urllib.parse.quote(station_clean)}&to={urllib.parse.quote(to_station)}"

        time_min = None
        transfer_count = None
        try:
            res = requests.get(url, headers=headers)
            res.raise_for_status()
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # ç¬¬1ãƒ«ãƒ¼ãƒˆã®æƒ…å ±ã‚’å–å¾—
            route1 = soup.select_one('#route01')
            if route1:
                # æ™‚é–“ã®æŠ½å‡º
                time_el = route1.select_one('.time')
                if time_el:
                    text = time_el.get_text()
                    m_hour_min = re.search(r'(\d+)æ™‚é–“(\d+)åˆ†', text)
                    m_min = re.search(r'(\d+)åˆ†', text)

                    if m_hour_min:
                        time_min = float(int(m_hour_min.group(1)) * 60 + int(m_hour_min.group(2)))
                    elif m_min:
                        time_min = float(m_min.group(1))
                
                # ä¹—ã‚Šæ›ãˆå›æ•°ã®æŠ½å‡º
                transfer_el = route1.select_one('.transfer')
                if transfer_el:
                    transfer_text = transfer_el.get_text()
                    m_transfer = re.search(r'(\d+)å›', transfer_text)
                    if m_transfer:
                        transfer_count = float(m_transfer.group(1))
                    elif 'ãªã—' in transfer_text:
                        transfer_count = 0.0
        except Exception as e:
            print(f"Error fetching data for {st}: {e}")

        station_data.append({
            'station_name': st,
            'time_to_target_min': time_min,
            'transfer_count': transfer_count
        })

        # é€²æ—è¡¨ç¤º
        if i % 10 == 0 or time_min is None:
            status = f"{time_min}åˆ†(ä¹—æ›{transfer_count}å›)" if time_min is not None else "å–å¾—å¤±æ•—"
            print(f"[{i}/{len(unique_stations)}] {st} -> {to_station}é§…: {status}")

        time.sleep(1)

    print("\nğŸ‰ å…¨é§…ã®å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    return pd.DataFrame(station_data)
